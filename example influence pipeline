import pandas as pd
import numpy as np
from scipy.stats import logistic
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder

from src.fairness.fairness_influence import evaluate_patterns
from src.influence import LogisticInfluence
from src.profiling.empty_detection import empty_detection
from src.profiling.outlier_detection import OutlierDetector
from src.profiling.influence_detection import InfluenceOutlierDetector


def pattern_to_readable(pattern, columns):
    readable = []
    for col_idx, val in pattern.items():
        col_name = columns[col_idx] if isinstance(col_idx, int) else col_idx
        if isinstance(val, pd.Interval):
            readable.append(f"{col_name} âˆˆ {val}")
        else:
            readable.append(f"{col_name} = {val}")
    return readable


# === 1. read data ===
df = pd.read_csv('adult.csv')

# === 2. Data cleaning ===
df = df.replace('?', np.nan)
df = df.dropna()

# select attribute
categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']
numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']

# Encode dataset
df_encoded = pd.get_dummies(df[categorical_cols])
X = pd.concat([df[numerical_cols], df_encoded], axis=1).astype(float)

# labeling data
y = (df['income'] == '>50K').astype(int).values

# scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# === 3. Missing Value detection ===
print("\n==== Missing Value Detection ====")
mv_report = empty_detection().report(df)
print(mv_report)

# === 4. Outlier detection ===
print("\n==== Outlier Detection (Z-score) ====")
outlier_idx = OutlierDetector(method='zscore', threshold=40).detect(X_train)
print("Outlier indices:", np.unique(outlier_idx[0]))

# === 5. influence Function detection ===
print("\n==== influence Function Detection ====")
model = LogisticRegression(max_iter=500).fit(X_train, y_train)
infl_detector = InfluenceOutlierDetector(model, X_train, y_train)
infl = infl_detector.detect(X_test[:5], y_test[:5])

# === 6. influence Function on fairness ===
logistic_influence = LogisticInfluence(model, X_train, y_train)
X_train_infl = logistic_influence.average_influence(X_test[:5], y_test[:5])
X_train_raw = pd.DataFrame(scaler.inverse_transform(pd.DataFrame(X_train)))
print(X_train_raw)
X_train_raw['influence'] = X_train_infl

top_patterns = evaluate_patterns(X_train_raw, min_support=0.05, top_k=5)
for i, p in enumerate(top_patterns):

    print(f"Pattern {i + 1}:")
    readable = pattern_to_readable(p['pattern'], df.columns)
    for cond in readable:
        print("  -", cond)
    print(
        f"  Support: {p['support']:.2%}, Responsibility: {p['responsibility']:.3f}, Interestingness: {p['interestingness']:.3f}")